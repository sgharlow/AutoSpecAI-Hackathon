"""
Comprehensive Structured Logging Utilities for AutoSpec.AI

This module provides advanced logging capabilities with structured JSON format,
correlation IDs, performance metrics, and integration with AWS CloudWatch.

Usage:
    from shared.logging_utils import get_logger, LogContext, log_performance
    
    logger = get_logger('my_function')
    
    with LogContext(request_id='123', user_id='user456'):
        logger.info('Processing started', extra={'step': 'validation'})
        
    @log_performance('document_processing')
    def process_document():
        # Your function logic
        pass
"""

import json
import logging
import time
import functools
import traceback
from datetime import datetime, timezone
from typing import Dict, Any, Optional, Union, Callable
from contextlib import contextmanager
import threading
import boto3
from botocore.exceptions import ClientError

# Thread-local storage for correlation context
_context = threading.local()

class StructuredFormatter(logging.Formatter):
    """Custom JSON formatter for structured logging."""
    
    def __init__(self, service_name: str = None, environment: str = None):
        super().__init__()
        self.service_name = service_name or 'autospec-ai'
        self.environment = environment or 'unknown'
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record as structured JSON."""
        
        # Base log structure
        log_entry = {
            'timestamp': datetime.fromtimestamp(record.created, tz=timezone.utc).isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'service': self.service_name,
            'environment': self.environment
        }
        
        # Add correlation context if available
        context = get_correlation_context()
        if context:
            log_entry['context'] = context
        
        # Add AWS Lambda context if available
        if hasattr(record, 'aws_request_id'):\n            log_entry['aws_request_id'] = record.aws_request_id\n        if hasattr(record, 'function_name'):\n            log_entry['function_name'] = record.function_name\n        if hasattr(record, 'function_version'):\n            log_entry['function_version'] = record.function_version\n        \n        # Add performance metrics if available\n        if hasattr(record, 'duration_ms'):\n            log_entry['performance'] = {\n                'duration_ms': record.duration_ms,\n                'operation': getattr(record, 'operation', 'unknown')\n            }\n        \n        # Add extra fields from the log call\n        if hasattr(record, 'extra_fields') and record.extra_fields:\n            log_entry.update(record.extra_fields)\n        \n        # Add exception information if present\n        if record.exc_info:\n            log_entry['exception'] = {\n                'type': record.exc_info[0].__name__ if record.exc_info[0] else None,\n                'message': str(record.exc_info[1]) if record.exc_info[1] else None,\n                'stack_trace': traceback.format_exception(*record.exc_info)\n            }\n        \n        # Add location information for debug logs\n        if record.levelno <= logging.DEBUG:\n            log_entry['location'] = {\n                'file': record.filename,\n                'line': record.lineno,\n                'function': record.funcName\n            }\n        \n        return json.dumps(log_entry, default=str, separators=(',', ':'))\n\nclass StructuredLogger:\n    \"\"\"Enhanced logger with structured logging capabilities.\"\"\"\n    \n    def __init__(self, logger: logging.Logger, service_name: str = None):\n        self.logger = logger\n        self.service_name = service_name or 'autospec-ai'\n    \n    def _log_with_extra(self, level: int, message: str, extra: Dict[str, Any] = None, **kwargs):\n        \"\"\"Log with extra structured fields.\"\"\"\n        if extra is None:\n            extra = {}\n        \n        # Merge kwargs into extra\n        extra.update(kwargs)\n        \n        # Create a log record with extra fields\n        record = self.logger.makeRecord(\n            name=self.logger.name,\n            level=level,\n            fn='',\n            lno=0,\n            msg=message,\n            args=(),\n            exc_info=None\n        )\n        record.extra_fields = extra\n        \n        self.logger.handle(record)\n    \n    def debug(self, message: str, **kwargs):\n        \"\"\"Log debug message with structured data.\"\"\"\n        self._log_with_extra(logging.DEBUG, message, **kwargs)\n    \n    def info(self, message: str, **kwargs):\n        \"\"\"Log info message with structured data.\"\"\"\n        self._log_with_extra(logging.INFO, message, **kwargs)\n    \n    def warning(self, message: str, **kwargs):\n        \"\"\"Log warning message with structured data.\"\"\"\n        self._log_with_extra(logging.WARNING, message, **kwargs)\n    \n    def error(self, message: str, **kwargs):\n        \"\"\"Log error message with structured data.\"\"\"\n        self._log_with_extra(logging.ERROR, message, **kwargs)\n    \n    def critical(self, message: str, **kwargs):\n        \"\"\"Log critical message with structured data.\"\"\"\n        self._log_with_extra(logging.CRITICAL, message, **kwargs)\n    \n    def exception(self, message: str, **kwargs):\n        \"\"\"Log exception with full traceback.\"\"\"\n        extra = kwargs.copy()\n        record = self.logger.makeRecord(\n            name=self.logger.name,\n            level=logging.ERROR,\n            fn='',\n            lno=0,\n            msg=message,\n            args=(),\n            exc_info=True\n        )\n        record.extra_fields = extra\n        self.logger.handle(record)\n    \n    def log_user_action(self, action: str, user_id: str = None, **kwargs):\n        \"\"\"Log user action for audit purposes.\"\"\"\n        self.info(f\"User action: {action}\", \n                 action=action, \n                 user_id=user_id or get_correlation_context().get('user_id'),\n                 audit=True,\n                 **kwargs)\n    \n    def log_api_request(self, method: str, path: str, status_code: int = None, \n                       duration_ms: float = None, **kwargs):\n        \"\"\"Log API request with structured data.\"\"\"\n        self.info(f\"API {method} {path}\",\n                 http_method=method,\n                 http_path=path,\n                 http_status_code=status_code,\n                 duration_ms=duration_ms,\n                 **kwargs)\n    \n    def log_database_operation(self, operation: str, table: str = None, \n                              duration_ms: float = None, **kwargs):\n        \"\"\"Log database operation with metrics.\"\"\"\n        self.info(f\"Database {operation}\",\n                 db_operation=operation,\n                 db_table=table,\n                 duration_ms=duration_ms,\n                 **kwargs)\n    \n    def log_external_service_call(self, service: str, operation: str,\n                                 duration_ms: float = None, success: bool = True, **kwargs):\n        \"\"\"Log external service call with metrics.\"\"\"\n        level = logging.INFO if success else logging.WARNING\n        self._log_with_extra(level, f\"External service call: {service}.{operation}\",\n                           service=service,\n                           operation=operation,\n                           duration_ms=duration_ms,\n                           success=success,\n                           **kwargs)\n    \n    def log_performance_metric(self, operation: str, duration_ms: float, **kwargs):\n        \"\"\"Log performance metric.\"\"\"\n        self.info(f\"Performance: {operation}\",\n                 operation=operation,\n                 duration_ms=duration_ms,\n                 metric_type='performance',\n                 **kwargs)\n    \n    def log_business_event(self, event_type: str, **kwargs):\n        \"\"\"Log business event for analytics.\"\"\"\n        self.info(f\"Business event: {event_type}\",\n                 event_type=event_type,\n                 business_event=True,\n                 **kwargs)\n\ndef get_logger(name: str, service_name: str = None, environment: str = None) -> StructuredLogger:\n    \"\"\"Get a structured logger instance.\"\"\"\n    \n    # Get or create logger\n    logger = logging.getLogger(name)\n    \n    # Only configure if not already configured\n    if not logger.handlers:\n        # Set level based on environment\n        if environment == 'dev':\n            logger.setLevel(logging.DEBUG)\n        elif environment == 'staging':\n            logger.setLevel(logging.INFO)\n        else:\n            logger.setLevel(logging.WARNING)\n        \n        # Create handler with structured formatter\n        handler = logging.StreamHandler()\n        formatter = StructuredFormatter(service_name, environment)\n        handler.setFormatter(formatter)\n        \n        logger.addHandler(handler)\n        logger.propagate = False\n    \n    return StructuredLogger(logger, service_name)\n\ndef set_correlation_context(**context):\n    \"\"\"Set correlation context for current thread.\"\"\"\n    if not hasattr(_context, 'correlation'):\n        _context.correlation = {}\n    _context.correlation.update(context)\n\ndef get_correlation_context() -> Dict[str, Any]:\n    \"\"\"Get correlation context for current thread.\"\"\"\n    return getattr(_context, 'correlation', {})\n\ndef clear_correlation_context():\n    \"\"\"Clear correlation context for current thread.\"\"\"\n    if hasattr(_context, 'correlation'):\n        _context.correlation.clear()\n\n@contextmanager\ndef LogContext(**context):\n    \"\"\"Context manager for correlation context.\"\"\"\n    # Save current context\n    previous_context = get_correlation_context().copy()\n    \n    try:\n        # Set new context\n        set_correlation_context(**context)\n        yield\n    finally:\n        # Restore previous context\n        clear_correlation_context()\n        if previous_context:\n            set_correlation_context(**previous_context)\n\ndef log_performance(operation_name: str = None):\n    \"\"\"Decorator to log function performance.\"\"\"\n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            op_name = operation_name or f\"{func.__module__}.{func.__name__}\"\n            logger = get_logger(func.__module__)\n            \n            start_time = time.time()\n            try:\n                result = func(*args, **kwargs)\n                duration_ms = (time.time() - start_time) * 1000\n                logger.log_performance_metric(op_name, duration_ms, success=True)\n                return result\n            except Exception as e:\n                duration_ms = (time.time() - start_time) * 1000\n                logger.log_performance_metric(op_name, duration_ms, success=False, error=str(e))\n                raise\n        return wrapper\n    return decorator\n\ndef log_aws_operation(service_name: str, operation_name: str = None):\n    \"\"\"Decorator to log AWS service operations.\"\"\"\n    def decorator(func: Callable) -> Callable:\n        @functools.wraps(func)\n        def wrapper(*args, **kwargs):\n            op_name = operation_name or func.__name__\n            logger = get_logger(func.__module__)\n            \n            start_time = time.time()\n            try:\n                result = func(*args, **kwargs)\n                duration_ms = (time.time() - start_time) * 1000\n                logger.log_external_service_call(service_name, op_name, duration_ms, True)\n                return result\n            except ClientError as e:\n                duration_ms = (time.time() - start_time) * 1000\n                error_code = e.response.get('Error', {}).get('Code', 'Unknown')\n                logger.log_external_service_call(\n                    service_name, op_name, duration_ms, False,\n                    aws_error_code=error_code,\n                    aws_error_message=str(e)\n                )\n                raise\n            except Exception as e:\n                duration_ms = (time.time() - start_time) * 1000\n                logger.log_external_service_call(\n                    service_name, op_name, duration_ms, False,\n                    error_type=type(e).__name__,\n                    error_message=str(e)\n                )\n                raise\n        return wrapper\n    return decorator\n\nclass CloudWatchLogsHandler(logging.Handler):\n    \"\"\"Custom handler to send structured logs to CloudWatch.\"\"\"\n    \n    def __init__(self, log_group_name: str, log_stream_name: str = None):\n        super().__init__()\n        self.log_group_name = log_group_name\n        self.log_stream_name = log_stream_name or f\"lambda-{datetime.now().strftime('%Y%m%d')}\"\n        self.logs_client = boto3.client('logs')\n        self._sequence_token = None\n        self._ensure_log_stream()\n    \n    def _ensure_log_stream(self):\n        \"\"\"Ensure log stream exists.\"\"\"\n        try:\n            # Create log group if it doesn't exist\n            try:\n                self.logs_client.create_log_group(logGroupName=self.log_group_name)\n            except self.logs_client.exceptions.ResourceAlreadyExistsException:\n                pass\n            \n            # Create log stream if it doesn't exist\n            try:\n                self.logs_client.create_log_stream(\n                    logGroupName=self.log_group_name,\n                    logStreamName=self.log_stream_name\n                )\n            except self.logs_client.exceptions.ResourceAlreadyExistsException:\n                # Get the sequence token for existing stream\n                response = self.logs_client.describe_log_streams(\n                    logGroupName=self.log_group_name,\n                    logStreamNamePrefix=self.log_stream_name,\n                    limit=1\n                )\n                if response['logStreams']:\n                    self._sequence_token = response['logStreams'][0].get('uploadSequenceToken')\n        \n        except Exception as e:\n            # Log setup error but don't fail\n            print(f\"Warning: CloudWatch Logs setup failed: {e}\")\n    \n    def emit(self, record: logging.LogRecord):\n        \"\"\"Send log record to CloudWatch.\"\"\"\n        try:\n            log_event = {\n                'timestamp': int(record.created * 1000),\n                'message': self.format(record)\n            }\n            \n            put_kwargs = {\n                'logGroupName': self.log_group_name,\n                'logStreamName': self.log_stream_name,\n                'logEvents': [log_event]\n            }\n            \n            if self._sequence_token:\n                put_kwargs['sequenceToken'] = self._sequence_token\n            \n            response = self.logs_client.put_log_events(**put_kwargs)\n            self._sequence_token = response.get('nextSequenceToken')\n            \n        except Exception as e:\n            # Don't let logging errors break the application\n            print(f\"Warning: Failed to send log to CloudWatch: {e}\")\n\ndef configure_lambda_logging(function_name: str, environment: str = None,\n                           enable_cloudwatch: bool = False,\n                           log_group_name: str = None):\n    \"\"\"Configure logging for Lambda function.\"\"\"\n    \n    # Clear any existing handlers\n    root_logger = logging.getLogger()\n    for handler in root_logger.handlers[:]:\n        root_logger.removeHandler(handler)\n    \n    # Create structured formatter\n    formatter = StructuredFormatter(function_name, environment)\n    \n    # Console handler (for CloudWatch Logs)\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)\n    root_logger.addHandler(console_handler)\n    \n    # Optional CloudWatch handler for centralized logging\n    if enable_cloudwatch and log_group_name:\n        try:\n            cloudwatch_handler = CloudWatchLogsHandler(\n                log_group_name=log_group_name,\n                log_stream_name=f\"{function_name}-{datetime.now().strftime('%Y%m%d')}\"\n            )\n            cloudwatch_handler.setFormatter(formatter)\n            root_logger.addHandler(cloudwatch_handler)\n        except Exception as e:\n            print(f\"Warning: Could not setup CloudWatch handler: {e}\")\n    \n    # Set log level\n    if environment == 'dev':\n        root_logger.setLevel(logging.DEBUG)\n    elif environment == 'staging':\n        root_logger.setLevel(logging.INFO)\n    else:\n        root_logger.setLevel(logging.WARNING)\n    \n    # Disable propagation to avoid duplicate logs\n    root_logger.propagate = False\n    \n    return get_logger(function_name, function_name, environment)\n\n# Convenience function for Lambda initialization\ndef init_lambda_logging(context, environment: str = None) -> StructuredLogger:\n    \"\"\"Initialize logging for Lambda function.\"\"\"\n    function_name = context.function_name if context else 'unknown'\n    env = environment or 'unknown'\n    \n    logger = configure_lambda_logging(function_name, env)\n    \n    # Set correlation context with Lambda info\n    if context:\n        set_correlation_context(\n            aws_request_id=context.aws_request_id,\n            function_name=context.function_name,\n            function_version=context.function_version,\n            memory_limit=context.memory_limit_in_mb,\n            remaining_time_ms=context.get_remaining_time_in_millis()\n        )\n    \n    return logger